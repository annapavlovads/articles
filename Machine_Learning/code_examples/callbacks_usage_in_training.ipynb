{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "callbacks_usage_in_training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/foobar167/articles/blob/master/Machine_Learning/code_examples/callbacks_usage_in_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lGbzH8SrcE8K",
        "colab_type": "code",
        "outputId": "6a96aa04-1eb9-425a-e94f-577a208b9282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the newest nightly build of TensorFlow\n",
        "!pip install tf-nightly-2.0-preview\n",
        "#!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly-2.0-preview\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/9f/4bb6f12c8960fa24b576daeaf02bc03b725b0673d990f1e4b8293d9bb196/tf_nightly_2.0_preview-2.0.0.dev20190424-cp36-cp36m-manylinux1_x86_64.whl (86.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 86.8MB 413kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.7.1)\n",
            "Collecting google-pasta>=0.1.2 (from tf-nightly-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/bb/f1bbc131d6294baa6085a222d29abadd012696b73dcbf8cf1bf56b9f082a/google_pasta-0.1.5-py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 27.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.1.0)\n",
            "Collecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/42/d4da1a4e7f123f7ee77087529f4567a9e003d4fa52e4e34c2e8aa8b5de3a/tb_nightly-1.14.0a20190425-py3-none-any.whl (3.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.1MB 1.2MB/s \n",
            "\u001b[?25hCollecting wrapt>=1.11.1 (from tf-nightly-2.0-preview)\n",
            "  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.33.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.0.7)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.16.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.0.9)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.15.0)\n",
            "Collecting tensorflow-estimator-2.0-preview (from tf-nightly-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/ef/c050a0dd0b1855b30a3568264888fcaa7a87c42e4dfda6036657a5bff029/tensorflow_estimator_2.0_preview-1.14.0.dev2019042300-py2.py3-none-any.whl (421kB)\n",
            "\u001b[K    100% |████████████████████████████████| 430kB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview) (0.15.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tf-nightly-2.0-preview) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-2.0-preview) (40.9.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n",
            "Successfully built wrapt\n",
            "\u001b[31mthinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-pasta, tb-nightly, wrapt, tensorflow-estimator-2.0-preview, tf-nightly-2.0-preview\n",
            "  Found existing installation: wrapt 1.10.11\n",
            "    Uninstalling wrapt-1.10.11:\n",
            "      Successfully uninstalled wrapt-1.10.11\n",
            "Successfully installed google-pasta-0.1.5 tb-nightly-1.14.0a20190425 tensorflow-estimator-2.0-preview-1.14.0.dev2019042300 tf-nightly-2.0-preview-2.0.0.dev20190424 wrapt-1.11.1\n",
            "2.0.0-dev20190424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CGkd6Ga-whot",
        "colab_type": "code",
        "outputId": "4801e222-1339-40ad-97ea-1b343d82bb52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-dev20190424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rru1mXMYcInx",
        "colab_type": "code",
        "outputId": "ee63830d-633d-4184-f8c2-a9767820262c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1468
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Just train to 90% accuracy and stop.\n",
        "class myCallback1(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy') > 0.9):\n",
        "            print('\\nReached 90% accuracy, so cancelling training!')\n",
        "            self.model.stop_training = True\n",
        "\n",
        "# Not useful for wavelike training.\n",
        "class myCallback2(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.patience = 10\n",
        "        self.curr_patience = 0\n",
        "        self.curr_evaluate = [float('inf')]\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        evaluate = model.evaluate(x_test, y_test)\n",
        "        print(evaluate[-1], self.curr_patience, self.curr_evaluate[-1])\n",
        "        if evaluate[-1] > self.curr_evaluate[-1]:\n",
        "            self.curr_patience += 1\n",
        "        self.curr_evaluate = evaluate\n",
        "        if self.curr_patience >= self.patience:\n",
        "            print('\\nModel has started to overfit, so cancelling training')\n",
        "            self.model.stop_training = True\n",
        "\n",
        "# Use EarlyStopping callback to stop training before overfitting\n",
        "myCallback3 = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "callback = myCallback2()  # select callback\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist  # get link on the MNIST dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()  # load data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # normalize the model\n",
        "\n",
        "# Build model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(x_train, y_train, epochs=100, callbacks=[callback])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/100\n",
            "10000/10000 [==============================] - 1s 53us/sample - loss: 0.4240 - accuracy: 0.8487\n",
            "0.8487 0 inf\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4765 - accuracy: 0.8311\n",
            "Epoch 2/100\n",
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.4033 - accuracy: 0.8470\n",
            "0.847 0 0.8487\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3566 - accuracy: 0.8697\n",
            "Epoch 3/100\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.3739 - accuracy: 0.8699\n",
            "0.8699 0 0.847\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3209 - accuracy: 0.8818\n",
            "Epoch 4/100\n",
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.3352 - accuracy: 0.8782\n",
            "0.8782 1 0.8699\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2986 - accuracy: 0.8895\n",
            "Epoch 5/100\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.3239 - accuracy: 0.8833\n",
            "0.8833 2 0.8782\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2779 - accuracy: 0.8967\n",
            "Epoch 6/100\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.3289 - accuracy: 0.8818\n",
            "0.8818 3 0.8833\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2633 - accuracy: 0.9023\n",
            "Epoch 7/100\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.3334 - accuracy: 0.8843\n",
            "0.8843 3 0.8818\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2504 - accuracy: 0.9067\n",
            "Epoch 8/100\n",
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.3304 - accuracy: 0.8846\n",
            "0.8846 4 0.8843\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2387 - accuracy: 0.9108\n",
            "Epoch 9/100\n",
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.3368 - accuracy: 0.8836\n",
            "0.8836 5 0.8846\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2297 - accuracy: 0.9142\n",
            "Epoch 10/100\n",
            "10000/10000 [==============================] - 1s 53us/sample - loss: 0.3225 - accuracy: 0.8886\n",
            "0.8886 5 0.8836\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.2211 - accuracy: 0.9167\n",
            "Epoch 11/100\n",
            "10000/10000 [==============================] - 1s 55us/sample - loss: 0.3364 - accuracy: 0.8835\n",
            "0.8835 6 0.8886\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.2121 - accuracy: 0.9201\n",
            "Epoch 12/100\n",
            "10000/10000 [==============================] - 1s 54us/sample - loss: 0.3242 - accuracy: 0.8914\n",
            "0.8914 6 0.8835\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.2061 - accuracy: 0.9228\n",
            "Epoch 13/100\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.3428 - accuracy: 0.8822\n",
            "0.8822 7 0.8914\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.1970 - accuracy: 0.9254\n",
            "Epoch 14/100\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.3583 - accuracy: 0.8897\n",
            "0.8897 7 0.8822\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1900 - accuracy: 0.9284\n",
            "Epoch 15/100\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.3355 - accuracy: 0.8923\n",
            "0.8923 8 0.8897\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1839 - accuracy: 0.9308\n",
            "Epoch 16/100\n",
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.3771 - accuracy: 0.8828\n",
            "0.8828 9 0.8923\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1783 - accuracy: 0.9320\n",
            "Epoch 17/100\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.3435 - accuracy: 0.8922\n",
            "0.8922 9 0.8828\n",
            "\n",
            "Model has started to overfit, so cancelling training\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1736 - accuracy: 0.9352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f69de16ba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "laHBjCXbcIwv",
        "colab_type": "code",
        "outputId": "2acd946a-4fb9-44ed-d6a3-3e0ed23267d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluate model. Old evaluation.\n",
        "print(model.evaluate(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.3435 - accuracy: 0.8922\n",
            "[0.34347014693021777, 0.8922]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2JF7S1NvcI5h",
        "colab_type": "code",
        "outputId": "3b8b0235-b6b2-42a0-ac9c-5ac8c2c78dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluate model. New evaluation.\n",
        "print(model.evaluate(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.3435 - accuracy: 0.8922\n",
            "[0.34347014693021777, 0.8922]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u9W4NjYgCDab",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}